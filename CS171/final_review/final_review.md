# Final

## Basic Concepts
### Task environment (PEAS)
- performance (measure)
- environment
- actuators
- sensors

### Agent Concepts
**Agent:** Perceives environment by sensors, acts by actuators
**Percept:** Agent's perceptual inputs at any given instant
**Percept Sequence:** Complete history of everything agnet has perceived
**Rational Agent:** Agents that acts to maximize its expected performance measure
**Deterministic Environment:** Next state of environment is fixed by current state and action
**Dynamic Environment:** Environment can change while agent is deliberating
**Performance Measure:** Evaluates any given sequence of environment states for utility
**Agent Function:**Maps any given percept sequence to an action
**Abstraction:** Process of removing detail from a representation
**Fully Observable:** Sensors give complete state of environment at each time point

### Path-Finding Search Concepts
**State Space:** All states reachable from the intial state by a sequence of actions
**Frontier:** Set of all leaf nodes available for expansion at any given time
**Uninformed Search:** Uses no additional information beyond problem definition
**Informed Search:** Uses problem-specific knowledge beyond problem definition
**Optimal Search:** Guaranteed to find lowest cost among all solution
**Complete Search:** Guaranteed to find a solution if one is accessible
**Expand a state:** Apply each legal action to state, generating a new set of states
**Branching Factor:** Maximum number of successors of any node
**Heuristic Function:** Estimates cost of cheapest path from current state to goal state
**A* Search:** Tries to minimize the total estimated solution cost
**Greedy Best-first Search:** Tries to expand the node believed to be closest to the goal
**Consistent Heuristic: **For n's a successor of n from action a, h(n) <= cost(n,a,n') + h(n')
**Admissible Heuristic:** Never over-estimates cost of cheapest path to a goal state
##### admissible:
A heuristic h(n) is admissible if for every node n, $ h(n)\leq h^{*}(n)$.


h*(n): the true cost to reach the goal state from n

##### consistent:
A heuristic is consistent (or monotone) if for every node n, every
successor n' of n generated by any action a,
$h(n) \leq c(n,a,n') + h(n')$

### Adversarial (Game) Search Concepts
**Game Tree: **Tree where nodes are game states and edges are game moves
**Cut-off Test:** Function that decides when to stop exploring this search branch
**Alpha-Beta Pruning:** Returns same move as MiniMax, but may prune more branches
**Weighted Linear Function:** Vector dot product of a weight vector and a state feature vector
**Zero-sum Game:** In all game instances, total pay-off summed over all player is the same
**MiniMax Algorithm:** Optimal strategy for 2-player zero-sum games of perfect information, but impractical given limited time to make each move
**Game Strategy:** Function that specifies a player's move in every possible game state
**Heuristic Evaluation Function:** Approximates the value of a game state(i.e., of a game position)

### Constraint Satisfaction Problem(CSP) Concepts
**Solution to a CSP:** A complete and consistent assignment
**Complete Assignment:** Every variable is associated with a value
**Constraint Graph:** Nodes correspond to variables, links connect variables that participate in a constraint
**Arc Consistency:** All values in a variable's domain satisfy its binary constraints
**Forward Checking:** When variable X is assigned, delete any value of other variable that is inconsistent with the assigned value of X
**Assignment:** Associates values with some or all variables
**Node Consistency:** All values in a variable's domain satisfy its unary constraints
**Domain:** Set of allowed values for some variable
**Constraint:** Specifies an allowable combination of variable values
**Consistent Assignment:** The values assigned to variables do not violate any constraints

#### True and false:
##### True:
- A **Constraint satisfaction problem (CSP)** consists of a set of variables, a set of domains (one for each variable), and a set of constraints that specify allowable combinations of values.
- The nodes of a **constraint graph** correspond to variables of the problem, and a link connects any two variables that participate in a constraint.
- A **constraint** consists of a pair < scope, rel>, where scope is a tuple of variables that participate and rel defines the values those variables can take on.
- Performing **constraint propagation** involves using the constraints to reduce the number of legal values for a variable, which in turn can reduce the legal values for another variable, and so on.
- A variable in a CSP is** arc-consistent** iff, for each value in its domain and each of its binary constraints, that constraint is satisfied by that domain value together with some value in the domain of the other variable in that constraint.
- The** minimum-remaining-values (MRV) **heuristic chooses the **variable** with the fewest remaining legal values to assign next.
- The **least-constraining-value heuristic** prefers the** value** that rules out the fewest choices for the neighboring variables in the constraint graph.
- The **min-conflicts** heuristic for local search prefers the **value** that results in the minimum number of conflicts with other variables.

##### False:
- A **consistent assignment** is one in which every variable is assigned.
	- Actually, this is Complete Assignment. For this one, the values assigned to variables do not violate any constraints.
- A **complete assignment** is one that does not violate any constraints.
	- this is the consistent assignment
- A **partial assignment** is one that violates only some of the constraints.
	- acutally: some values are assigned
- Constraint satisfaction problems are **semi-decidable** because they may never terminate if the problem has no legal solution.
	- no. it will terminate
- The **degree heuristic** is used to set the temperature in methods for solving CSPs based on Simulated Annealing.
	- no. it select	**variable**	that	is	involved	in	the	largest	number	of	constraints	on	other	unassigned	variables.
- The **min-conflicts** heuristic is rarely used because it is only effective when the constraint graph is a tree.
	- it is used in hill-climbing
	
### Logic Concepts
**Logic:** Formal symbol system for representation and inference
**KB**: knowledge base - a set of sentences or facts
**model: ** Possible world that assigns TRUE or FALSE to each proposition.
**Valid:** True in every possible world
**Semantics:** Defines the truth of each sentence in each possible world

**Satisfiable"** True in at least one possible world
**unsatisfiable: **A sentence is unsatisfiable if it is false in all model.
**Syntax:** Specifies all the sentences that are well formed
**Entailment:** The idea that a sentence follows logically from other sentences
**inference**: deriving sentences from other sentences
**Sound:** inference system derives only entailed sentences
**Complete:** Inference system can derive any sentence that is entailed
**Proof: **Chain of inference rule conclusions leading to a desired sentence.
**Conjunctive Normal Form:** A sentence expressed as a conjuction of clauses (disjuncts)

### Probability concepts and formulae
**Probability Theory:** Assigns each sentence a degree of belief raning from 0 to 1
**Conditional independence:** P(a^b|c) = P(a|c)P(b|c)
**Independence:** P(a^b)=P(a)P(b)
**Product rule(chain rule):** P(a^b^c) = P(a|b^c)P(b|c)P(c)
**Conditional probability:** Degree of belief accorded after some evidence is obtained
**Unconditional probability:** Degree of belief accorded without any other information
**Factored representation:** A possible world is represented by variable/value pairs
**Random variable:** Takes values from its domain with specified probabilities
**Bayes' rule:** P(a|b) = P(b|a)P(a)/P(b)
**Joint probability distribution:** Gives probability of all combinations of values of all variables

### Machine learning concepts
**Learning:** improves performance of future tasks after observing the world
**Decision Boundary:** Surface in a high-dimensional space that separates the classes
**Factored Representation:** Fixed set, list, or vector of features/attributes paried with a value
**Overfitting:** Choose an over-complex model based on irrelevant data patterns
**Cross-validation:** Randomly split the data into a training set and a test set
**Unsupervised Learning:** Agent learns patterns in the input with no explicit feedback
**Supervised Learning:** Agent observes input-output pairs & learns to map input to output
**Test Set:** Examples distinct from training set, used to estimate accuracy
**Training set:** Example input-output pairs, from which to discover a hypothesis
**Classification:** Supervised learning with a discrete set of possible output values
**Regression:** Supervised learning with numeric output values
- **Linear Classifier**: Tests $w\cdot f > 0$, where $w$ is a weight vector and $f$ is a feature vector
- **Naïve Bayes Classifier**: Tests $P (C) \prod_{i} P(X_i | C)$ Where C is a class label and $X_i$ are features
- **Decision Tree**: Internal nodes test a value of an attribute, leaf nodes=class labels
- **Information Gain**: Expected reduction in entropy from testing an attribute value
- **Decision Boundary**: Surface in a high-dimensional space that separates the classes

#### True and false:
##### True:
- A **decision tree** can learn and represent any Boolean function.
- **Overfitting** is a general phenomenon that occurs with all types of learners.
- An agent is **learning **if it improves its performance on future tasks after
making observations about the world.
##### False:
- A **linear classifier** (perceptron) can learn and represent any Boolean function.
	- this is the decision tree. linear classifier cut into two.. so cannot represent
- A** Naïve Bayes classifier **can learn and represent only axis-parallel classes.
- **“Naive Bayes”** is called “naive” because only naive people ever use it.
- The **information gain** from an attribute A is how much classifier accuracy improves when attribute A is added to the example feature vectors in the training set.
- **Cross-validation** is a way to improve the accuracy of a learned hypothesis by reducing over-fitting using Ockham’s razor.
	- it cannot reduce overfitting

## Search Properties

| search alg |chracteristics| Complete? | Time complexity| Space complexity| Optimal?|
|--------|--------|
|Depth-First|Frontier = Last In First Out (LIFO) queue;** Goal-Test when inserted**.|No: fails in loops/infinite-depth spaces|$O(b^m)$ with m =maximum depth of space|$O(bm)$, i.e., linear space!|No: It may find a non-optimal goal first
|Breadth-First|FIFO, **goal test after node is popped off**|yes, it always reaches a goal|$O(b^d)$|$O(b^d)$(keeps every node in memory, either in frontier or on a path to frontier)|Yes. It is only optimal if path cost is a non-decreasing function of depth, i.e. $f(d)\ge f(d-1)$|
|Uniform-Cost|**goal test after node is popped off**. FIFO, Frontier = queue ordered by path cost. Equivalent to breadth-first if all step costs all equal.|Yes, it b is finite and step cost $\ge ε \gt 0$ (otherwise it can get stuck in infinite loops)|$O(b^{\lfloor 1+C^*/ε \rfloor })\approx O(b^{d+1})$|$O(b^{\lfloor 1+C^*/ε \rfloor })\approx O(b^{d+1})$|Yes, for any step cost $≥ ε > 0$.|
|Depth-Limited|**Goal test when inserted**. Only search until depth L|No|$O(b^l)$|O(bl)|No
|iterative deepening|**Goal test when inserted**. Increase depth iteratively. - Inherits the memory advantage of DFS; - Has the completeness property of BFS|Yes|$O(b^d)$|$O(bd)$|Yes, if cost is a non-decreasing function only of depth.
|bidirectional (if applicable)|simultaneously search forward from S and backwards from G \n – stop when both “meet in the middle” \n – need to keep track of the intersection of 2 open sets of nodes|Yes|$O(2 b^{(d/2)}) = O(b^{ (d/2)})$| $O(2 b^{(d/2)}) = O(b^{ (d/2)})$| Yes|
|greedy best-first search|Same for differnt goal test strategy. $h(n)$| no(tree)| $O(b^m)$ |$O(b^m)$|no|
|A*search| **goal test after node is popped off.** $f(n)=g(n)+h(n)$|yes|$O(b^m)$|$O(b^m)$|Yes. With: Tree-Search, admissible heuristic; Graph-Search,consistent heuristic

## Alpha Beta Pruning
![AB Pruning](abPruning.png "" "width:70%")
**alpha**: maximizer. Only use alpha to note the level of Max.
**beta**: minimizer. use beta to note the level of Min.
Update alpha or beta of a node after finishing search it's children
Every time look at a child, compare alpha and beta. When alpha > beta, prune!

## Constraint Satisfaction Problem
example from 2012 fq
![csp graph](cspgraph.png "" "width:60%")
### Forward Checking
After a value of a variable is assigned, **delete the violated values of its neighbors**
(Check only neighbors; delete any inconsistent values)

![csp forward checking](cspforwardchecking.png "" "width:70%")
In this graph, MA neighbors are VT, NH, CT, RI. It will check those neighbors and only cross out their inconsistent values.

### Arc Consistency(AC-3)
Like Forward Checking, but **exhausive** until quiescence.
An	Arc	X→ Y is consistent if for every	value x	of X there is some value y of Y consistent with	x.
Arc	consistency	detects	failure	earlier	than FC

![csp arcconsistency](csparcconsistency.png "" "width:70%")
In this example, CT and RI are assigned values. Steps are:
1. check MA, cross out R and G because they are violated
2. MA can only take B, check VT and NH, cross out B from VT and NH.
3. Because there are >1 choices for ME, don't corss out anything from ME.

### Minimum Remaining Values Heuristic (MRV)
A.k.a. most constrained	variable heuristic
Heuristic Rule:** choose variable	with the fewest legal moves**
will immediately detect	failure	if X has no legal values

![cspmrv](cspmrv.png "" "width:70%")
In this example, becasue CT and MA both have fewest available values (2), they will be selected.

### Degree Heuristic
Heuristic Rule:	**select variable	that is involved in the largest number of constraints on other	unassigned variables.**

![csp degree h](degreeh.png "" "width:70%")
in this example, after RI is assigned, RI is removed from the constraints of MA. The number of constraints on other unassigned variables for both MA and NH is 3. So we should choose MA, NH.

### Min-Conflicts Heuristic

**Select new value that results in a minimum number of conflicts with the other variables**
![csp min-conflicts](minconflict.png "" "width:70%")
In this example, we count the number of conflicts of each value
R: 0
G: 3 (RI,VT,NH)
B: 1 (CT)
so we should choose R


## Logic
### Knowledge engineering process
1. Identify the task.
2. Assemble the relevant knowledge.
3. Decide on a vocabulary of predicates, functions, and constants.
4. Encode general knowledge about the domain.
5. Encode a description of the specific problem instance.
6. Pose queries to the inference procedure and get answers.
7. Debug the knowledge base.


#### logical equivalence
![logical equivalence](logicalEquivalence.png "" "width:70%")

**Example from 2012 fq**
$[\neg ( Q ⇒ P ) ] ⇔ P$
- ==implication elimination==
$[¬ (¬Q\lor P )]\Leftrightarrow P $
$(Q \land \neg P)\Leftrightarrow P$
$[(Q\land \neg P)\Rightarrow P] \land [P \Rightarrow (Q\land \neg P)]$
$[\neg (Q \land \neg P) \lor P] \land [\neg P \lor (Q\land \neg P)]$
- == De Morgan & distributivity of $\lor$ over $\land$==
$(\neg Q \lor P \lor P) \land [(\neg P\lor Q)\land (\neg P \lor \neg P) ]$
$(\neg Q \lor P) \land [(\neg P \lor Q) \land \neg P]$
- ==Distributivity of $\land$over $\lor$ ==
$(\neg Q \lor P) \land [(\neg P \land \neg P) \lor (Q \land \neg P)]$
$(\neg Q \lor P) \land [\neg P \lor (Q\land \neg P)$
- ==distributivity of $\lor$ over $\land$==
$(\neg Q \lor P) \land [(\neg P \lor Q) \land (\neg P \lor \neg P)] $
$(\neg Q \lor P) \land (\neg P \lor Q) \land \neg P $
- ==Distributivity of $\land$over $\lor$ ==
$[(\neg Q \land \neg P)\lor (\neg Q \land Q)\lor (P\land \neg P)\lor (P\land Q)]\land \neg P$
$[(\neg Q \land \neg P)\lor (P\land Q)]\land \neg P$
- ==Distributivity of $\land$over $\lor$ ==
$(\neg Q \land \neg P\land \neg P)\lor (P\land Q \land \neg P)$
- ==$(P\land Q \land \neg P)$ should be false ==
$(\neg Q \land \neg P)$

### truth table
![truth table](truthtable.png "" "width:60%")

###Syntax of FOL: Basic elements
- Constant Symbols
- Predicate Symbols
- Function Symbols
- Model (world) = set of domain objects, relations, functions
- Intepretation
- variables
- quantifiers: know how to convert one to another
	- order(scope)
	- De morgan's Rule
	- Generalized De Morgan's Rule

### FOPL and English correspondences
key words: 
-  -- people do/is x -- always has a "=>"
- All, Every, For... -- with "for all"
- there is, a, some... -- with "exist"
- exist always do not have "=>"

1. ==All persons are mortal.==
	![s1](s1.png "" "width:50%")
2. ==Fifi has a sister who is a cat.==
	![s2](s2.png "" "width:50%")
3.  ==For every food, there is a person who eats that food.==
	![s3](s3.png "" "width:60%")
4. ==every person eats every food.==
	![s4](s4.png "" "width:50%")
5. ==all greedy kings are evil.==
	![s5](s5.png "" "width:55%")
6. ==everyone has a favorite food.==
	![s6](s6.png "" "width:50%")
7. ==There is someone at UCI who is smart.==
	![s7](s7.png "" "width:50%")
8. ==Every one at UCI is smart.==
	![s8](s8.png "" "width:50%")
9. ==Every person eats some food.==
	![s9](s9.png "" "width:55%")
10. ==some person eats some food.==
	![s10](s10.png "" "width:50%")

## Probability
### Axioms of probability:
- 0 <= P(a) <= 1
- P(NOT(a)) = 1 – P(a)
- P(true) = 1
- P(false) = 0
- P(A OR B) = P(A) + P(B) – P(A AND B)

#### And Probability
$P(A, B) = P(A ˄ B) = P(A) + P(B) - P(A ˅ B)$
#### Or Probability
$P(A ˅B) = P(A) + P(B) – P(A ˄ B)$

#### Conditional Probability
$P(A | B) = \frac{P(A, B)}{ P(B)}$

#### Product Rule
- aka **Chain Rule**
- $P(a,b) = P(a|b)P(b) = P(b|a)P(a)$ 

Using Product Rule
$ P(a,b,c) = P(a,b|c)P(c) = P(a|b,c)P(b,c)$
$
P(a,b,c|d,e) = P(a|b,c,d,e)P(b,c|d,e)
$
#### Sum Rule
- aka **Law of Total Probability**
$
P(A) = \sum_{B,C}P(A,B,C)
$
e.g.
$
P(b) = \sum_{a}\sum_{c}\sum_{d}P(a,b,c,d)
$
$
P(a,d) = \sum_{b}\sum_{c}P(a,b,c,d)
$
- Given a set of probabilities $P(CatchFish, Day, Lake)$
- Where:
	- CatchFish = {true, false}
	- Day = {mon, tues, wed, thurs, fri, sat, sun}
	- Lake = {buel lake, ralph lake, crystal lake}
– Need to find P(CatchFish = True):
	- $P(CatchFish = true) = Σ_{day} Σ_{lake} P(CatchFish = true, day, lake)$

#### Bayes' Rule
$
P(B|A) = \frac{P(A|B)P(B)}{P(A)}
$
#### Derivation of Bayes' Rule
- start from Product Rule:
	- $P(a,b) = 
	P(a|b)P(b) =  
	\frac{P(b|a)P(a)}{P(b)} \cdot P(b) =P(b|a)P(a) = 
	\frac{P(b,a)}{P(a)}\cdot P(a) =
	P(a,b)$
	
	- $P(a,b) = 
	P(b|a)P(a) = 
	\frac{P(a|b)P(b)}{P(a)}\cdot P(a)= P(a|b)P(b) = \frac{P(a,b)}{P(b)}\cdot P(b) = P(a,b)
	$

- Isolate Equality on Right Side:
	- $P(a|b)P(b) = 
	P(b|a)P(a) = 
	\frac{P(a,b)}{P(a)}\cdot P(a)=
	P(a,b)=
	\frac{P(a,b)}{P(b)}\cdot P(b) =
	P(a|b)\cdot P(b)
	 $
	 
- Divide through by P(b)
	- $P(a|b) = P(b|a)P(a)/P(b)=
	\frac{P(a,b)}{P(a)} \cdot P(a) / P(b)=
	\frac{P(a,b)}{P(b)}
	$

#### Conditional Independence
- X, Y independent given Z
- $p(X=x,Y=y|Z=z) = p(X=x|Z=z) p(Y=y|Z=z)$ 
for all x,y,z
- **Equivalent**: $p(X|Y,Z) = p(X|Z) or p(Y|X,Z) = p(Y|Z)$
- **Intuition**: X has no additional info about Y beyond Z’s

## machine learning
### Bayesian Networks
(Product) chain rule:
$P(a,b) = P(a|b)P(b) = P(b|a)P(a)\\
 P(a,b,c) = P(a,b|c)P(c) = P(a|b,c)P(b,c)\\
P(a,b,c|d,e) = P(a|b,c,d,e)P(b,c|d,e)\\
P(A, B, C, D) = P(D | C, B, A) P(C | B, A) P(B | A) P(A)$
![bayes](bayes.png "" "width:60%")

### naive baysian classifier
$P(C)\Pi P(x|C)\\
 P(c=1|x) = \frac{P(c=1, x)}{P(c=1, x) + P(c=0, x)}\\
H(C|v) = H(C|v=yes)P(v=Yes) + H(C|v=No)P(v=No)$


### Entropy: 
$$$ H = \sum_{x} p(x)\log p(x)$$$

IG (Information gain): $$$ H - \sum_{B} P(B)H(x|B)$$$


- oeverfitting and underfitting
- Disjoint validation data sets
- knn Decision boundary

### K-Nearest-Neighbor Classifier

example from 2013 fq
![kNearestNeighborClassifier](kNearestNeighborClassifier.png "" "width:70%")

we count the number of points from the circle.
when k = 1, we count the one near the star, it is W, so W
when k = 3, we count the 3 nearest points from the star, 1 W and 2B, so B
when k = 5, we count 5 nearest points from the star, 3 W and 2 B, so W